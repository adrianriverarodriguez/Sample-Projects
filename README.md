# Semantic Modeling ‚Äì Community Responses
## üßæ Keyword Analysis & Thematic Seeding

To support human thematic analysis and enrich the semantic modeling phase, I developed a custom keyword analysis pipeline:

- Used `CountVectorizer` and basic NLP preprocessing (lowercasing, stopword removal, tokenization) to extract high-frequency unigrams and bigrams from open-ended survey responses.
- Conducted keyword-in-context (KWIC) inspection to explore how frequently used terms (e.g., ‚Äúsupport,‚Äù ‚Äúaccess,‚Äù ‚Äúfair,‚Äù ‚Äúincluded‚Äù) were used across different participants.
- Manually reviewed top terms to inform the construction of an **equity-themed keyword dictionary**.
- This dictionary was then used to:
  - Seed initial coding categories for manual thematic analysis
  - Interpret and validate topics generated by BERTopic

The keyword script is available in the `keyword_analysis.ipynb` notebook and provides an interpretable foundation that bridges qualitative analysis with scalable NLP techniques.
## üß† Symantec Model
- **Text Preprocessing**: Custom cleaning pipeline using `spaCy` for tokenization, lemmatization, and stopword removal.
- **Topic Modeling**: 
  - `BERTopic` with `TF-IDF` and `CountVectorizer` backends
  - Dimensionality reduction via `UMAP`
  - Density-based clustering via `HDBSCAN`
- **Visualization**: Interactive topic visualizations using BERTopic's built-in tools and `matplotlib`
- **Integration with Admin Data**: Qualitative topics linked with quantitative metrics to enrich analysis of equity conditions
## üìÅ Files
-  `semantic_tagging_creative(1).ipynb`: Symantec analysis notebook
- `outputs/`: Final Report Available on Request
## üí° Use Cases
- Summarizing qualitative feedback at scale
- Linking NLP-driven insights to decision-making frameworks
- Supporting equity-focused resource allocation using community voice
## ‚ö†Ô∏è Note on Data

This project uses privately protected data to preserve confidentiality. No personally data is shared in this repository.
## üîß Dependencies
- `bertopic`
- `scikit-learn`
- `hdbscan`
- `umap-learn`
- `spaCy`
- `matplotlib`
- `pandas`
Install all requirements:
```bash
pip install -r requirements.txt
